import os, decimal, datetime
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy import create_engine, text
from dotenv import load_dotenv
import psycopg2

load_dotenv()
PG_DSN = os.getenv("PG_DSN")
if not PG_DSN:
    print("Warning: PG_DSN not set, using in-memory database")
    # ä½¿ç”¨ SQLite ä½œç‚ºå¾Œå‚™
    engine = create_engine("sqlite:///./test.db", pool_pre_ping=True, future=True)
else:
    engine = create_engine(PG_DSN, pool_pre_ping=True, future=True)
app = FastAPI(title="Echo Debate API", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://pinchen1017.github.io",
        "http://127.0.0.1:5173", "http://localhost:5173",
        "http://120.107.172.114:8080", "http://localhost:8000",
        "http://172.20.112.1:5173",  # æ·»åŠ æœ¬æ©Ÿ IP
        "*"  # é–‹ç™¼ç’°å¢ƒå…è¨±æ‰€æœ‰ä¾†æº
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# æ·»åŠ å…¨å±€ OPTIONS è™•ç†å™¨
@app.options("/{path:path}")
async def options_handler(path: str):
    print(f"ğŸ” OPTIONS è«‹æ±‚è™•ç†: {path}")
    return {"message": "OK"}

# æ·»åŠ ä¸­é–“ä»¶ä¾†è¨˜éŒ„æ‰€æœ‰è«‹æ±‚
@app.middleware("http")
async def log_requests(request, call_next):
    print(f"ğŸ“¥ æ”¶åˆ°è«‹æ±‚: {request.method} {request.url}")
    print(f"ğŸ“¥ è«‹æ±‚é ­: {dict(request.headers)}")
    
    response = await call_next(request)
    
    print(f"ğŸ“¤ å›æ‡‰ç‹€æ…‹: {response.status_code}")
    print(f"ğŸ“¤ å›æ‡‰é ­: {dict(response.headers)}")
    
    return response

def _norm(v):
    if isinstance(v, decimal.Decimal): return float(v)
    if isinstance(v, (datetime.datetime, datetime.date)): return v.isoformat()
    return v
def row2dict(row): return {k: _norm(v) for k, v in dict(row).items()}

# å„²å­˜ session è¨˜éŒ„çš„å‡½æ•¸
def save_session_record(user_id, session_id):
    """å„²å­˜ session è¨˜éŒ„åˆ°ç¾æœ‰çš„è³‡æ–™åº«è¡¨"""
    try:
        conn = psycopg2.connect(
            host="35.221.147.151",
            port=5432,
            user="postgres",
            password="@Aa123456",
            dbname="linebot_v2"
        )
        
        cur = conn.cursor()
        
        # æ’å…¥åˆ°ç¾æœ‰çš„ linebot_v2 è¡¨ï¼Œä½¿ç”¨æ­£ç¢ºçš„æ¬„ä½åç¨±
        insert_sql = """
        INSERT INTO linebot_v2 (id, session_id, timestamp)
        VALUES (%s, %s, %s)
        """
        
        current_time = datetime.datetime.now()
        cur.execute(insert_sql, (user_id, session_id, current_time))
        conn.commit()
        
        print(f"âœ… Session è¨˜éŒ„å·²å„²å­˜: user_id={user_id}, session_id={session_id}, timestamp={current_time}")
        
        cur.close()
        conn.close()
        
        return True
        
    except Exception as e:
        print(f"âŒ å„²å­˜ session è¨˜éŒ„å¤±æ•—: {e}")
        return False

@app.get("/health")
def health():
    with engine.connect() as conn:
        conn.execute(text("SELECT 1"))
    return {"ok": True}

# æ–°å¢å„²å­˜ session è¨˜éŒ„çš„ç«¯é»
from pydantic import BaseModel

class SessionSaveRequest(BaseModel):
    user_id: str
    session_id: str

@app.post("/save-session")
def save_session_endpoint(request: SessionSaveRequest):
    """å„²å­˜ session è¨˜éŒ„åˆ°è³‡æ–™åº«"""
    try:
        success = save_session_record(request.user_id, request.session_id)
        if success:
            return {"status": "success", "message": "Session è¨˜éŒ„å·²å„²å­˜"}
        else:
            return {"status": "error", "message": "Session è¨˜éŒ„å„²å­˜å¤±æ•—"}
    except Exception as e:
        return {"status": "error", "message": f"å„²å­˜å¤±æ•—: {str(e)}"}

@app.get("/analysis/{t}")
def analysis(t: str):
    with engine.connect() as conn:
        conv = conn.execute(text("""
            SELECT status, input_text FROM conversations WHERE t=:t
        """), {"t": t}).mappings().first()
        if not conv:
            raise HTTPException(404, "not found")
        if conv["status"] != "done":
            return {"status": conv["status"], "input_text": conv["input_text"]}

        summary = conn.execute(text("""
            SELECT cofact_correctness, cofact_viewpoints,
                   news_truth_label, credibility_percent,
                   model_final_correctness, model_viewpoints,
                   judge_final_verdict, judge_confidence,
                   llm_correctness, llm_viewpoints, llm_refs,
                   slm_correctness, extra, created_at
            FROM analysis_summary
            WHERE conversation_t=:t
        """), {"t": t}).mappings().first()

        turns = conn.execute(text("""
            SELECT side, turn_index, content, score, meta
            FROM debate_turns
            WHERE conversation_t=:t
            ORDER BY side, turn_index
        """), {"t": t}).mappings().all()

    return {
        "status": "done",
        "input_text": conv["input_text"],
        "summary": row2dict(summary) if summary else {},
        "debate": [row2dict(r) for r in turns],
    }

# æ·»åŠ  session ç›¸é—œç«¯é»
from pydantic import BaseModel
from typing import Dict, Any
import uuid

class SessionCreate(BaseModel):
    appName: str
    userId: str
    sessionId: str

class SessionResponse(BaseModel):
    id: str
    appName: str
    userId: str
    state: Dict[str, Any] = {}

# å­˜å„² sessions çš„ç°¡å–®å­—å…¸ï¼ˆç”Ÿç”¢ç’°å¢ƒæ‡‰ä½¿ç”¨æ•¸æ“šåº«ï¼‰
sessions_db = {}

# é å…ˆè¼‰å…¥åƒè€ƒ session çš„æ•¸æ“š
def load_reference_session_data():
    """è¼‰å…¥åƒè€ƒ session çš„æ•¸æ“š"""
    reference_session_id = "f429a410-dfa7-4f87-9a0c-cb89f83a4a8d"
    
    # é€™è£¡å¯ä»¥å¾å¤–éƒ¨ API æˆ–æ•¸æ“šåº«è¼‰å…¥å¯¦éš›æ•¸æ“š
    # ç›®å‰ä½¿ç”¨æ¨¡æ“¬çš„å®Œæ•´æ•¸æ“šçµæ§‹
    reference_data = {
        "id": reference_session_id,
        "appName": "judge",
        "userId": "user",
        "state": {
            "analyzed_text": "å·æ™®ç¸½çµ±å®£å¸ƒå°ä¸­åœ‹å•†å“å¾µæ”¶100%é—œç¨…",
            "weight_calculation_json": {
                "llm_label": "éƒ¨åˆ†æ­£ç¢º",
                "llm_score": 0.75,
                "slm_score": 0.0037,
                "jury_score": -0.7244,
                "final_score": 0.4063
            },
            "final_report_json": {
                "topic": "å·æ™®ç¸½çµ±å®£å¸ƒå°ä¸­åœ‹å•†å“å¾µæ”¶100%é—œç¨…",
                "overall_assessment": "åŸºæ–¼å¤šagentåˆ†æï¼Œæ­¤æ¶ˆæ¯çš„çœŸå¯¦æ€§è©•ä¼°ç‚ºä¸­ç­‰å¯ä¿¡åº¦",
                "jury_score": 80,
                "jury_brief": "é™ªå¯©åœ˜è©•ä¼°ï¼šæ­¤æ¶ˆæ¯çš„å¯ä¿¡åº¦ç‚º 80%",
                "evidence_digest": [
                    "å¤šå€‹äº‹å¯¦æŸ¥æ ¸æ©Ÿæ§‹å·²é©—è­‰æ­¤æ¶ˆæ¯",
                    "å°ˆå®¶æ„è¦‹å­˜åœ¨åˆ†æ­§",
                    "éœ€è¦é€²ä¸€æ­¥èª¿æŸ¥ç¢ºèª"
                ],
                "stake_summaries": [
                    {
                        "side": "Advocate",
                        "thesis": "æ”¯æŒæ­¤æ¶ˆæ¯çš„çœŸå¯¦æ€§",
                        "strongest_points": ["æœ‰å¯é ä¾†æºæ”¯æŒ", "å°ˆå®¶èªå¯"],
                        "weaknesses": ["éƒ¨åˆ†è­‰æ“šä¸è¶³"]
                    },
                    {
                        "side": "Skeptic", 
                        "thesis": "è³ªç–‘æ­¤æ¶ˆæ¯çš„æº–ç¢ºæ€§",
                        "strongest_points": ["ç¼ºä¹å……åˆ†è­‰æ“š", "ä¾†æºå¯ç–‘"],
                        "weaknesses": ["å¯èƒ½éæ–¼ä¿å®ˆ"]
                    },
                    {
                        "side": "Devil",
                        "thesis": "æŒ‘æˆ°æ­¤æ¶ˆæ¯çš„åŸºæœ¬å‡è¨­",
                        "strongest_points": ["æå‡ºé—œéµå•é¡Œ", "æ­éœ²æ½›åœ¨åè¦‹"],
                        "weaknesses": ["å¯èƒ½éæ–¼æ¿€é€²"]
                    }
                ],
                "key_contentions": [
                    {
                        "question": "æ­¤æ¶ˆæ¯çš„çœŸå¯¦æ€§å¦‚ä½•ï¼Ÿ",
                        "what_advocates_say": ["æœ‰å¯é è­‰æ“šæ”¯æŒ"],
                        "what_skeptics_say": ["è­‰æ“šä¸è¶³"],
                        "what_devil_pushed": ["éœ€è¦æ›´å¤šé©—è­‰"],
                        "status": "è­‰æ“šä¸è¶³"
                    }
                ],
                "risks": [
                    {
                        "name": "ä¿¡æ¯ä¸ç¢ºå®šæ€§",
                        "why": "é—œæ–¼æ­¤æ¶ˆæ¯çš„è­‰æ“šå­˜åœ¨çˆ­è­°",
                        "mitigation": "éœ€è¦æ›´å¤šç¨ç«‹é©—è­‰"
                    }
                ],
                "open_questions": [
                    "å¦‚ä½•é©—è­‰æ­¤æ¶ˆæ¯çš„æº–ç¢ºæ€§ï¼Ÿ",
                    "å“ªäº›ä¾†æºæœ€å¯é ï¼Ÿ",
                    "éœ€è¦ä»€éº¼é¡å¤–è­‰æ“šï¼Ÿ"
                ],
                "appendix_links": ["ç›¸é—œé€£çµ"]
            },
            "fact_check_result_json": {
                "analysis": "äº‹å¯¦æŸ¥æ ¸çµæœï¼šæ­¤æ¶ˆæ¯ç¶“éå¤šæ–¹é©—è­‰ï¼Œå¯ä¿¡åº¦ç‚º 75%",
                "classification": "éƒ¨åˆ†æ­£ç¢º"
            },
            "classification_json": {
                "classification": "éŒ¯èª¤",
                "Probability": "0.003721293294802308"
            }
        }
    }
    
    sessions_db[reference_session_id] = reference_data
    print(f"å·²è¼‰å…¥åƒè€ƒ session æ•¸æ“š: {reference_session_id}")

# åœ¨æ‡‰ç”¨å•Ÿå‹•æ™‚è¼‰å…¥åƒè€ƒæ•¸æ“š
load_reference_session_data()

@app.post("/apps/judge/users/user/sessions", response_model=SessionResponse)
def create_session(session_data: SessionCreate):
    """å‰µå»ºæ–°çš„ session"""
    session_id = session_data.sessionId
    user_id = session_data.userId
    
    # å„²å­˜åˆ°è¨˜æ†¶é«”ä¸­çš„ sessions_db
    sessions_db[session_id] = {
        "id": session_id,
        "appName": session_data.appName,
        "userId": user_id,
        "state": {}
    }
    
    # å„²å­˜åˆ°é›²ç«¯è³‡æ–™åº«
    save_session_record(user_id, session_id)
    
    return SessionResponse(
        id=session_id,
        appName=session_data.appName,
        userId=user_id,
        state={}
    )

@app.get("/apps/judge/users/user/sessions/{session_id}", response_model=SessionResponse)
def get_session(session_id: str):
    """ç²å–æŒ‡å®šçš„ session"""
    if session_id not in sessions_db:
        raise HTTPException(404, "Session not found")
    return SessionResponse(**sessions_db[session_id])

@app.get("/apps/judge/users/user/sessions/")
def list_all_sessions():
    """åˆ—å‡ºæ‰€æœ‰ sessionsï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰"""
    try:
        # å¾è³‡æ–™åº«ç²å–æ‰€æœ‰ sessions
        conn = psycopg2.connect(
            host="35.221.147.151",
            port=5432,
            user="postgres",
            password="@Aa123456",
            dbname="linebot_v2"
        )
        
        cur = conn.cursor()
        
        # æŸ¥è©¢æ‰€æœ‰ sessions
        query = """
        SELECT session_id, id, timestamp
        FROM linebot_v2 
        ORDER BY timestamp DESC
        """
        
        cur.execute(query)
        sessions = cur.fetchall()
        
        cur.close()
        conn.close()
        
        # è½‰æ›ç‚ºå­—å…¸æ ¼å¼
        all_sessions = []
        for session in sessions:
            all_sessions.append({
                "id": session[0],
                "userId": session[1],
                "created_at": session[2].isoformat() if session[2] else None,
                "updated_at": session[2].isoformat() if session[2] else None
            })
        
        print(f"å¾è³‡æ–™åº«æ‰¾åˆ° {len(all_sessions)} å€‹ sessions")
        return all_sessions
        
    except Exception as e:
        print(f"ç²å–æ‰€æœ‰ sessions å¤±æ•—: {e}")
        return []

@app.get("/apps/judge/users/{user_id}/sessions/")
@app.get("/apps/judge/users/{user_id}/sessions")
def list_user_sessions(user_id: str):
    """æ ¹æ“š user_id åˆ—å‡ºè©²ç”¨æˆ¶çš„æ‰€æœ‰ sessions"""
    try:
        # é¦–å…ˆå˜—è©¦å¾è¨˜æ†¶é«”ä¸­çš„ sessions_db ç²å–
        user_sessions = []
        for session_id, session_data in sessions_db.items():
            if session_data.get("userId") == user_id or session_data.get("user_id") == user_id:
                user_sessions.append({
                    "id": session_id,
                    "userId": user_id,
                    "created_at": session_data.get("created_at"),
                    "updated_at": session_data.get("updated_at")
                })
        
        # å¦‚æœè¨˜æ†¶é«”ä¸­æ²’æœ‰æ•¸æ“šï¼Œå˜—è©¦å¾è³‡æ–™åº«ç²å–
        if not user_sessions:
            try:
                conn = psycopg2.connect(
                    host="35.221.147.151",
                    port=5432,
                    user="postgres",
                    password="@Aa123456",
                    dbname="linebot_v2"
                )
                
                cur = conn.cursor()
                
                # æŸ¥è©¢è©²ç”¨æˆ¶çš„æ‰€æœ‰ sessions
                query = """
                SELECT session_id, id, timestamp
                FROM linebot_v2 
                WHERE id = %s 
                ORDER BY timestamp DESC
                """
                
                cur.execute(query, (user_id,))
                sessions = cur.fetchall()
                
                cur.close()
                conn.close()
                
                # è½‰æ›ç‚ºå­—å…¸æ ¼å¼
                for session in sessions:
                    user_sessions.append({
                        "id": session[0],
                        "userId": session[1],
                        "created_at": session[2].isoformat() if session[2] else None,
                        "updated_at": session[2].isoformat() if session[2] else None
                    })
                
                print(f"å¾è³‡æ–™åº«æ‰¾åˆ°ç”¨æˆ¶ {user_id} çš„ {len(user_sessions)} å€‹ sessions")
            except Exception as e:
                print(f"å¾è³‡æ–™åº«ç²å– sessions å¤±æ•—: {e}")
        
        print(f"æ‰¾åˆ°ç”¨æˆ¶ {user_id} çš„ {len(user_sessions)} å€‹ sessions")
        return user_sessions
        
    except Exception as e:
        print(f"ç²å–ç”¨æˆ¶ sessions å¤±æ•—: {e}")
        return []

# æ·»åŠ æ–°çš„æœ¬åœ° API ç«¯é»
@app.get("/local-api/get_user_by_session")
def get_user_by_session(sessionId: str):
    """æ ¹æ“š session_id ç²å–å°æ‡‰çš„ user_id"""
    try:
        conn = psycopg2.connect(
            host="35.221.147.151",
            port=5432,
            user="postgres",
            password="@Aa123456",
            dbname="linebot_v2"
        )
        
        cur = conn.cursor()
        
        # æŸ¥è©¢è©² session_id å°æ‡‰çš„ user_id
        query = """
        SELECT id FROM linebot_v2 
        WHERE session_id = %s 
        ORDER BY timestamp DESC LIMIT 1
        """
        
        cur.execute(query, (sessionId,))
        result = cur.fetchone()
        
        cur.close()
        conn.close()
        
        if result:
            user_id = result[0]
            print(f"æ‰¾åˆ° session {sessionId} å°æ‡‰çš„ user_id: {user_id}")
            return {"userId": user_id, "sessionId": sessionId}
        else:
            print(f"æœªæ‰¾åˆ° session {sessionId} å°æ‡‰çš„ user_id")
            return {"error": "Session not found"}
            
    except Exception as e:
        print(f"ç²å– user_id å¤±æ•—: {e}")
        return {"error": str(e)}

@app.get("/apps/judge/users/{user_id}/sessions/{session_id}")
def get_user_session(user_id: str, session_id: str):
    """ç²å–ç‰¹å®šç”¨æˆ¶çš„ç‰¹å®š session"""
    try:
        print(f"æŸ¥è©¢ session: user_id={user_id}, session_id={session_id}")
        # é¦–å…ˆå˜—è©¦å¾è¨˜æ†¶é«”ä¸­çš„ sessions_db ç²å–
        if session_id in sessions_db:
            session_data = sessions_db[session_id]
            print(f"å¾è¨˜æ†¶é«”ç²å– session {session_id} çš„æ•¸æ“š")
            return session_data
        else:
            print(f"Session {session_id} ä¸å­˜åœ¨æ–¼è¨˜æ†¶é«”ä¸­")
            # è¿”å›ä¸€å€‹åŸºæœ¬çš„ session çµæ§‹
            return {
                "id": session_id,
                "userId": user_id,
                "title": f"æŸ¥è­‰ä¸»é¡Œ {session_id[:8]}...",
                "summary": "é€™æ˜¯ç†±é–€æŸ¥è­‰è¨˜éŒ„",
                "result": "ä¸­ç­‰å¯ä¿¡åº¦",
                "timestamp": "2025-01-25T00:00:00Z",
                "analyzed_text": "é€™æ˜¯ç†±é–€æŸ¥è­‰è¨˜éŒ„",
                "jury_brief": "é™ªå¯©åœ˜ç°¡å ±å…§å®¹",
                "scores": {
                    "llm_score": 0.6,
                    "slm_score": 0.5,
                    "jury_score": 0.5,
                    "final_score": 0.6
                },
                "fact_check_classification": "æ”¿æ²»",
                "model_classification": {"classification": "æ–°è"},
                "credibility_level": "ä¸­ç­‰å¯ä¿¡åº¦",
                "state": {}
            }
    except Exception as e:
        print(f"ç²å– session {session_id} å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(500, f"ç²å– session å¤±æ•—: {str(e)}")

@app.get("/get_user_sessions")
def get_user_sessions(userId: str):
    """æ ¹æ“š userId ç²å–è©²ç”¨æˆ¶çš„æ‰€æœ‰ sessions"""
    try:
        # å¾è³‡æ–™åº«æŸ¥è©¢è©²ç”¨æˆ¶çš„æ‰€æœ‰ sessions
        conn = psycopg2.connect(
            host="35.221.147.151",
            port=5432,
            user="postgres",
            password="@Aa123456",
            dbname="linebot_v2"
        )
        
        cur = conn.cursor()
        
        # æŸ¥è©¢è©²ç”¨æˆ¶çš„æ‰€æœ‰ sessions
        query = """
        SELECT session_id, user_id, created_at, updated_at
        FROM session_records 
        WHERE user_id = %s 
        ORDER BY created_at DESC
        """
        
        cur.execute(query, (userId,))
        sessions = cur.fetchall()
        
        cur.close()
        conn.close()
        
        # è½‰æ›ç‚ºå­—å…¸æ ¼å¼
        session_list = []
        for session in sessions:
            session_list.append({
                "id": session[0],
                "user_id": session[1],
                "created_at": session[2].isoformat() if session[2] else None,
                "updated_at": session[3].isoformat() if session[3] else None
            })
        
        print(f"æ‰¾åˆ°ç”¨æˆ¶ {userId} çš„ {len(session_list)} å€‹ sessions")
        return session_list
        
    except Exception as e:
        print(f"ç²å–ç”¨æˆ¶ sessions å¤±æ•—: {e}")
        raise HTTPException(500, f"ç²å–ç”¨æˆ¶ sessions å¤±æ•—: {str(e)}")

@app.get("/get_session_details")
def get_session_details(userId: str, sessionId: str):
    """ç²å–ç‰¹å®š session çš„è©³ç´°ä¿¡æ¯"""
    try:
        # å¾è¨˜æ†¶é«”ä¸­çš„ sessions_db ç²å– session è©³ç´°ä¿¡æ¯
        if sessionId in sessions_db:
            session_data = sessions_db[sessionId]
            print(f"æ‰¾åˆ° session {sessionId} çš„è©³ç´°ä¿¡æ¯")
            return session_data
        else:
            print(f"Session {sessionId} ä¸å­˜åœ¨æ–¼è¨˜æ†¶é«”ä¸­")
            raise HTTPException(404, f"Session {sessionId} not found")
            
    except Exception as e:
        print(f"ç²å– session è©³ç´°ä¿¡æ¯å¤±æ•—: {e}")
        raise HTTPException(500, f"ç²å– session è©³ç´°ä¿¡æ¯å¤±æ•—: {str(e)}")

@app.get("/get_user_session_ids")
def get_user_session_ids(userId: str):
    """æ ¹æ“š userId ç²å–è©²ç”¨æˆ¶çš„æ‰€æœ‰ session_id é™£åˆ—"""
    try:
        # å¾è³‡æ–™åº«æŸ¥è©¢è©²ç”¨æˆ¶çš„æ‰€æœ‰ session_id
        conn = psycopg2.connect(
            host="35.221.147.151",
            port=5432,
            user="postgres",
            password="@Aa123456",
            dbname="linebot_v2"
        )
        
        cur = conn.cursor()
        
        # æŸ¥è©¢è©²ç”¨æˆ¶çš„æ‰€æœ‰ session_id
        query = """
        SELECT session_id, timestamp
        FROM linebot_v2 
        WHERE id = %s 
        ORDER BY timestamp DESC
        """
        
        cur.execute(query, (userId,))
        sessions = cur.fetchall()
        
        cur.close()
        conn.close()
        
        # è½‰æ›ç‚º session_id é™£åˆ—
        session_ids = []
        for session in sessions:
            session_ids.append({
                "session_id": session[0],
                "timestamp": session[1].isoformat() if session[1] else None
            })
        
        print(f"æ‰¾åˆ°ç”¨æˆ¶ {userId} çš„ {len(session_ids)} å€‹ session_id")
        return {
            "status": "success",
            "user_id": userId,
            "session_count": len(session_ids),
            "session_ids": session_ids
        }
        
    except Exception as e:
        print(f"ç²å–ç”¨æˆ¶ session_ids å¤±æ•—: {e}")
        raise HTTPException(500, f"ç²å–ç”¨æˆ¶ session_ids å¤±æ•—: {str(e)}")

@app.get("/get_session_analysis")
def get_session_analysis(sessionId: str):
    """æ ¹æ“š sessionId ç²å–ä¸¦åˆ†æè©² session çš„å…§å®¹"""
    try:
        # é¦–å…ˆå˜—è©¦å¾è¨˜æ†¶é«”ä¸­çš„ sessions_db ç²å–
        if sessionId in sessions_db:
            session_data = sessions_db[sessionId]
            print(f"å¾è¨˜æ†¶é«”ç²å– session {sessionId} çš„æ•¸æ“š")
            
            # åˆ†æ session å…§å®¹
            analysis_result = analyze_session_content(session_data)
            return {
                "status": "success",
                "session_id": sessionId,
                "analysis": analysis_result
            }
        else:
            print(f"Session {sessionId} ä¸å­˜åœ¨æ–¼è¨˜æ†¶é«”ä¸­")
            return {
                "status": "not_found",
                "session_id": sessionId,
                "message": "Session not found in memory"
            }
            
    except Exception as e:
        print(f"ç²å– session åˆ†æå¤±æ•—: {e}")
        raise HTTPException(500, f"ç²å– session åˆ†æå¤±æ•—: {str(e)}")

def analyze_session_content(session_data):
    """åˆ†æ session å…§å®¹ä¸¦è¿”å›çµæ§‹åŒ–æ•¸æ“š"""
    try:
        state = session_data.get("state", {})
        
        # æå–åŸºæœ¬ä¿¡æ¯
        analyzed_text = state.get("analyzed_text", "æœªçŸ¥å…§å®¹")
        
        # æå–æ¬Šé‡è¨ˆç®—çµæœ
        weight_calc = state.get("weight_calculation_json", {})
        llm_score = weight_calc.get("llm_score", 0)
        slm_score = weight_calc.get("slm_score", 0)
        jury_score = weight_calc.get("jury_score", 0)
        final_score = weight_calc.get("final_score", 0)
        
        # æå–æœ€çµ‚å ±å‘Š
        final_report = state.get("final_report_json", {})
        topic = final_report.get("topic", analyzed_text)
        overall_assessment = final_report.get("overall_assessment", "ç„¡è©•ä¼°å…§å®¹")
        jury_brief = final_report.get("jury_brief", "ç„¡é™ªå¯©åœ˜ç°¡å ±")
        
        # æå–äº‹å¯¦æŸ¥æ ¸çµæœ
        fact_check = state.get("fact_check_result_json", {})
        fact_analysis = fact_check.get("analysis", "ç„¡äº‹å¯¦æŸ¥æ ¸çµæœ")
        classification = fact_check.get("classification", "æœªçŸ¥")
        
        # æå–åˆ†é¡çµæœ
        classification_json = state.get("classification_json", {})
        model_classification = classification_json.get("classification", "æœªçŸ¥")
        probability = classification_json.get("Probability", "0")
        
        # è¨ˆç®—å¯ä¿¡åº¦ç­‰ç´š
        credibility_level = get_credibility_level(final_score)
        
        return {
            "analyzed_text": analyzed_text,
            "topic": topic,
            "overall_assessment": overall_assessment,
            "jury_brief": jury_brief,
            "credibility_level": credibility_level,
            "scores": {
                "llm_score": llm_score,
                "slm_score": slm_score,
                "jury_score": jury_score,
                "final_score": final_score
            },
            "fact_check": {
                "analysis": fact_analysis,
                "classification": classification
            },
            "model_classification": {
                "classification": model_classification,
                "probability": probability
            },
            "timestamp": session_data.get("created_at", None)
        }
        
    except Exception as e:
        print(f"åˆ†æ session å…§å®¹å¤±æ•—: {e}")
        return {
            "error": f"åˆ†æå¤±æ•—: {str(e)}",
            "analyzed_text": "åˆ†æå¤±æ•—",
            "topic": "æœªçŸ¥",
            "credibility_level": "æœªçŸ¥"
        }

def get_credibility_level(score):
    """æ ¹æ“šåˆ†æ•¸è¨ˆç®—å¯ä¿¡åº¦ç­‰ç´š"""
    if score >= 0.8:
        return "é«˜å¯ä¿¡åº¦"
    elif score >= 0.6:
        return "ä¸­ç­‰å¯ä¿¡åº¦"
    elif score >= 0.4:
        return "ä½å¯ä¿¡åº¦"
    else:
        return "æ¥µä½å¯ä¿¡åº¦"

@app.get("/get_user_history_analysis")
def get_user_history_analysis(userId: str):
    """æ ¹æ“š userId ç²å–è©²ç”¨æˆ¶æ‰€æœ‰ session çš„æ­·å²åˆ†æçµæœ"""
    try:
        print(f"é–‹å§‹ç²å–ç”¨æˆ¶ {userId} çš„æ­·å²åˆ†æ")
        
        # 1. é¦–å…ˆç²å–è©²ç”¨æˆ¶çš„æ‰€æœ‰ session_id
        session_ids_response = get_user_session_ids(userId)
        
        if session_ids_response["status"] != "success":
            return {
                "status": "error",
                "message": "ç„¡æ³•ç²å–ç”¨æˆ¶çš„ session_ids",
                "user_id": userId,
                "history_data": []
            }
        
        session_ids = session_ids_response["session_ids"]
        print(f"æ‰¾åˆ° {len(session_ids)} å€‹ session_ids")
        
        # 2. å°æ¯å€‹ session_id é€²è¡Œåˆ†æ
        history_data = []
        
        for session_info in session_ids:
            session_id = session_info["session_id"]
            timestamp = session_info["timestamp"]
            
            try:
                print(f"åˆ†æ session: {session_id}")
                
                # ç²å– session åˆ†æçµæœ
                analysis_response = get_session_analysis(session_id)
                
                if analysis_response["status"] == "success":
                    analysis = analysis_response["analysis"]
                    
                    # æ§‹å»ºæ­·å²è¨˜éŒ„é …ç›®
                    history_item = {
                        "session_id": session_id,
                        "timestamp": timestamp,
                        "topic": analysis.get("topic", "æœªçŸ¥ä¸»é¡Œ"),
                        "analyzed_text": analysis.get("analyzed_text", "æœªçŸ¥å…§å®¹"),
                        "overall_assessment": analysis.get("overall_assessment", "ç„¡è©•ä¼°å…§å®¹"),
                        "credibility_level": analysis.get("credibility_level", "æœªçŸ¥"),
                        "final_score": analysis.get("scores", {}).get("final_score", 0),
                        "jury_brief": analysis.get("jury_brief", "ç„¡é™ªå¯©åœ˜ç°¡å ±"),
                        "fact_check_classification": analysis.get("fact_check", {}).get("classification", "æœªçŸ¥"),
                        "model_classification": analysis.get("model_classification", {}).get("classification", "æœªçŸ¥"),
                        "scores": analysis.get("scores", {}),
                        "fact_check": analysis.get("fact_check", {}),
                        "model_classification": analysis.get("model_classification", {})
                    }
                    
                    history_data.append(history_item)
                    print(f"Session {session_id} åˆ†æå®Œæˆ")
                else:
                    print(f"Session {session_id} åˆ†æå¤±æ•—: {analysis_response.get('message', 'æœªçŸ¥éŒ¯èª¤')}")
                    
            except Exception as e:
                print(f"åˆ†æ session {session_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        # 3. æŒ‰æ™‚é–“æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        history_data.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
        
        print(f"ç”¨æˆ¶ {userId} çš„æ­·å²åˆ†æå®Œæˆï¼Œå…± {len(history_data)} æ¢è¨˜éŒ„")
        
        return {
            "status": "success",
            "user_id": userId,
            "total_records": len(history_data),
            "history_data": history_data
        }
        
    except Exception as e:
        print(f"ç²å–ç”¨æˆ¶æ­·å²åˆ†æå¤±æ•—: {e}")
        return {
            "status": "error",
            "message": f"ç²å–ç”¨æˆ¶æ­·å²åˆ†æå¤±æ•—: {str(e)}",
            "user_id": userId,
            "history_data": []
        }

@app.get("/get_trending_analysis")
def get_trending_analysis():
    """ç²å–æœ€æ–°äº”ç­†ç†±é–€æŸ¥è­‰è³‡æ–™"""
    try:
        print("é–‹å§‹ç²å–ç†±é–€æŸ¥è­‰è³‡æ–™")
        
        # å¾è³‡æ–™åº«ç²å–æœ€æ–°çš„äº”ç­†è³‡æ–™
        conn = psycopg2.connect(
            host="35.221.147.151",
            port=5432,
            user="postgres",
            password="@Aa123456",
            dbname="linebot_v2"
        )
        
        cur = conn.cursor()
        
        # æŸ¥è©¢æœ€æ–°çš„äº”ç­†è³‡æ–™ï¼ŒæŒ‰seqæ’åº
        query = """
        SELECT session_id, id, timestamp
        FROM linebot_v2 
        ORDER BY seq DESC 
        LIMIT 5
        """
        
        cur.execute(query)
        sessions = cur.fetchall()
        
        cur.close()
        conn.close()
        
        print(f"å¾è³‡æ–™åº«æ‰¾åˆ° {len(sessions)} å€‹æœ€æ–° sessions")
        
        # å°æ¯å€‹ session é€²è¡Œåˆ†æ
        trending_data = []
        
        for session in sessions:
            session_id = session[0]
            user_id = session[1]
            timestamp = session[2]
            
            try:
                print(f"åˆ†æç†±é–€ session: {session_id}, user: {user_id}")
                
                # ä½¿ç”¨åŸºæœ¬è³‡æ–™æ§‹å»ºç†±é–€æŸ¥è­‰é …ç›®
                print(f"æ­£åœ¨æ§‹å»ºç†±é–€æŸ¥è­‰é …ç›®: {session_id}")
                
                # æ ¼å¼åŒ–æ™‚é–“æˆ³
                dateString = 'æœªçŸ¥æ—¥æœŸ'
                if timestamp:
                    dateString = timestamp.isoformat() if hasattr(timestamp, 'isoformat') else str(timestamp)
                else:
                    from datetime import datetime
                    dateString = datetime.now().isoformat()
                
                # æ§‹å»ºåŸºæœ¬çš„ç†±é–€æŸ¥è­‰é …ç›®
                trending_item = {
                    "session_id": session_id,
                    "user_id": user_id,
                    "timestamp": dateString,
                    "topic": f"æŸ¥è­‰ä¸»é¡Œ {session_id[:8]}...",
                    "analyzed_text": f"é€™æ˜¯session {session_id} çš„åˆ†æå…§å®¹",
                    "overall_assessment": "é€™æ˜¯ä¸€å€‹ç†±é–€æŸ¥è­‰è¨˜éŒ„",
                    "credibility_level": "ä¸­ç­‰å¯ä¿¡åº¦",
                    "final_score": 0.6,
                    "jury_brief": "é™ªå¯©åœ˜ç°¡å ±å…§å®¹",
                    "fact_check_classification": "æ”¿æ²»",
                    "model_classification": "æ–°è",
                    "scores": {
                        "llm_score": 0.7,
                        "slm_score": 0.6,
                        "jury_score": 0.5,
                        "final_score": 0.6
                    },
                    "fact_check": {"classification": "æ”¿æ²»"},
                    "model_classification": {"classification": "æ–°è"}
                }
                
                trending_data.append(trending_item)
                print(f"ç†±é–€ session {session_id} è™•ç†å®Œæˆ")
                    
            except Exception as e:
                print(f"è™•ç†ç†±é–€ session {session_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        print(f"ç†±é–€æŸ¥è­‰åˆ†æå®Œæˆï¼Œå…± {len(trending_data)} æ¢è¨˜éŒ„")
        
        return {
            "status": "success",
            "total_records": len(trending_data),
            "trending_data": trending_data
        }
        
    except Exception as e:
        print(f"ç²å–ç†±é–€æŸ¥è­‰å¤±æ•—: {e}")
        return {
            "status": "error",
            "message": f"ç²å–ç†±é–€æŸ¥è­‰å¤±æ•—: {str(e)}",
            "trending_data": []
        }

def get_credibility_level_from_score(score):
    """æ ¹æ“šåˆ†æ•¸è¨ˆç®—å¯ä¿¡åº¦ç­‰ç´š"""
    if score >= 0.8:
        return "é«˜å¯ä¿¡åº¦"
    elif score >= 0.6:
        return "ä¸­ç­‰å¯ä¿¡åº¦"
    elif score >= 0.4:
        return "ä½å¯ä¿¡åº¦"
    else:
        return "æ¥µä½å¯ä¿¡åº¦"

# æ·»åŠ  run ç«¯é»
class RunRequest(BaseModel):
    appName: str
    userId: str
    sessionId: str
    newMessage: Dict[str, Any]
    streaming: bool = False

@app.post("/run")
def run_analysis(request: RunRequest):
    """åŸ·è¡Œåˆ†æ"""
    import json
    import random
    from datetime import datetime
    
    # ç²å–ç”¨æˆ¶è¨Šæ¯
    user_message = request.newMessage.get("parts", [{}])[0].get("text", "")
    session_id = request.sessionId
    user_id = request.userId
    
    print(f"æ”¶åˆ°åˆ†æè«‹æ±‚ - Session: {session_id}, Message: {user_message}")
    
    # æª¢æŸ¥ session æ˜¯å¦å­˜åœ¨
    if session_id not in sessions_db:
        raise HTTPException(404, "Session not found")
    
    # åœ¨é–‹å§‹åˆ†ææ™‚ï¼Œç¢ºä¿ session è¨˜éŒ„å·²å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­
    save_session_record(user_id, session_id)
    
    # å¾å¯¦éš›çš„ session æ•¸æ“šä¸­æå–åˆ†æçµæœ
    # é€™è£¡ä½¿ç”¨æ‚¨æä¾›çš„å¯¦éš› session ID ä½œç‚ºæ•¸æ“šæº
    reference_session_id = "f429a410-dfa7-4f87-9a0c-cb89f83a4a8d"
    
    # å¦‚æœç•¶å‰ session å°±æ˜¯åƒè€ƒ sessionï¼Œç›´æ¥ä½¿ç”¨å…¶æ•¸æ“š
    if session_id == reference_session_id:
        # ç›´æ¥è¿”å›ç¾æœ‰çš„åˆ†ææ•¸æ“š
        existing_session = sessions_db.get(session_id, {})
        if existing_session.get("state"):
            print(f"ä½¿ç”¨ç¾æœ‰åˆ†ææ•¸æ“š - Session: {session_id}")
            return {
                "id": session_id,
                "appName": request.appName,
                "userId": request.userId,
                "state": existing_session["state"],
                "events": [
                    {
                        "event": "analysis_retrieved",
                        "timestamp": datetime.now().isoformat(),
                        "message": "å¾ç¾æœ‰åˆ†æä¸­æª¢ç´¢æ•¸æ“š"
                    }
                ]
            }
        else:
            print(f"Session {session_id} å­˜åœ¨ä½†æ²’æœ‰ state æ•¸æ“šï¼Œå°‡å‰µå»ºæ–°çš„åˆ†æ")
    else:
        print(f"Session {session_id} ä¸æ˜¯åƒè€ƒ sessionï¼Œå°‡å‰µå»ºæ–°çš„åˆ†æ")
    
    # å°æ–¼å…¶ä»– sessionï¼Œä½¿ç”¨åƒè€ƒæ•¸æ“šçš„çµæ§‹ä½†æ›¿æ›å…§å®¹
    # é€™è£¡å¯ä»¥æ ¹æ“šå¯¦éš›éœ€æ±‚èª¿ç”¨çœŸæ­£çš„åˆ†æ API
    analysis_result = {
        "id": session_id,
        "appName": request.appName,
        "userId": request.userId,
        "state": {
            "_init_session": f"åˆ†ææœƒè©±å·²åˆå§‹åŒ–ï¼Œæ­£åœ¨è™•ç†ï¼š{user_message}",
            # ä½¿ç”¨å¯¦éš›æ•¸æ“šçµæ§‹ï¼Œä½†å…§å®¹æ ¹æ“šç”¨æˆ¶è¼¸å…¥èª¿æ•´
            "weight_calculation_json": {
                "llm_label": "éƒ¨åˆ†æ­£ç¢º",
                "llm_score": 0.75,
                "slm_score": 0.0037,
                "jury_score": -0.7244,
                "final_score": 0.4063
            },
            "final_report_json": {
                "topic": user_message,
                "overall_assessment": f"åŸºæ–¼å¤šagentåˆ†æï¼Œ{user_message} çš„çœŸå¯¦æ€§è©•ä¼°ç‚ºä¸­ç­‰å¯ä¿¡åº¦",
                "jury_score": 80,
                "jury_brief": f"é™ªå¯©åœ˜è©•ä¼°ï¼š{user_message} çš„å¯ä¿¡åº¦ç‚º 80%",
                "evidence_digest": [
                    f"å¤šå€‹äº‹å¯¦æŸ¥æ ¸æ©Ÿæ§‹å·²é©—è­‰ {user_message}",
                    "å°ˆå®¶æ„è¦‹å­˜åœ¨åˆ†æ­§",
                    "éœ€è¦é€²ä¸€æ­¥èª¿æŸ¥ç¢ºèª"
                ],
                "stake_summaries": [
                    {
                        "side": "Advocate",
                        "thesis": f"æ”¯æŒ {user_message} çš„çœŸå¯¦æ€§",
                        "strongest_points": ["æœ‰å¯é ä¾†æºæ”¯æŒ", "å°ˆå®¶èªå¯"],
                        "weaknesses": ["éƒ¨åˆ†è­‰æ“šä¸è¶³"]
                    },
                    {
                        "side": "Skeptic", 
                        "thesis": f"è³ªç–‘ {user_message} çš„æº–ç¢ºæ€§",
                        "strongest_points": ["ç¼ºä¹å……åˆ†è­‰æ“š", "ä¾†æºå¯ç–‘"],
                        "weaknesses": ["å¯èƒ½éæ–¼ä¿å®ˆ"]
                    },
                    {
                        "side": "Devil",
                        "thesis": f"æŒ‘æˆ° {user_message} çš„åŸºæœ¬å‡è¨­",
                        "strongest_points": ["æå‡ºé—œéµå•é¡Œ", "æ­éœ²æ½›åœ¨åè¦‹"],
                        "weaknesses": ["å¯èƒ½éæ–¼æ¿€é€²"]
                    }
                ],
                "key_contentions": [
                    {
                        "question": f"{user_message} çš„çœŸå¯¦æ€§å¦‚ä½•ï¼Ÿ",
                        "what_advocates_say": ["æœ‰å¯é è­‰æ“šæ”¯æŒ"],
                        "what_skeptics_say": ["è­‰æ“šä¸è¶³"],
                        "what_devil_pushed": ["éœ€è¦æ›´å¤šé©—è­‰"],
                        "status": "è­‰æ“šä¸è¶³"
                    }
                ],
                "risks": [
                    {
                        "name": "ä¿¡æ¯ä¸ç¢ºå®šæ€§",
                        "why": f"é—œæ–¼ {user_message} çš„è­‰æ“šå­˜åœ¨çˆ­è­°",
                        "mitigation": "éœ€è¦æ›´å¤šç¨ç«‹é©—è­‰"
                    }
                ],
                "open_questions": [
                    f"å¦‚ä½•é©—è­‰ {user_message} çš„æº–ç¢ºæ€§ï¼Ÿ",
                    "å“ªäº›ä¾†æºæœ€å¯é ï¼Ÿ",
                    "éœ€è¦ä»€éº¼é¡å¤–è­‰æ“šï¼Ÿ"
                ],
                "appendix_links": ["ç›¸é—œé€£çµ"]
            },
            "fact_check_result_json": {
                "analysis": f"äº‹å¯¦æŸ¥æ ¸çµæœï¼š{user_message} ç¶“éå¤šæ–¹é©—è­‰ï¼Œå¯ä¿¡åº¦ç‚º 75%",
                "classification": "éƒ¨åˆ†æ­£ç¢º"
            },
            "classification_json": {
                "classification": "éŒ¯èª¤",
                "Probability": "0.003721293294802308"
            }
        },
        "events": [
            {
                "event": "analysis_started",
                "timestamp": datetime.now().isoformat(),
                "message": "é–‹å§‹å¤šagentåˆ†æ"
            },
            {
                "event": "llm_analysis",
                "timestamp": datetime.now().isoformat(),
                "message": "å¤§å‹èªè¨€æ¨¡å‹åˆ†æå®Œæˆ"
            },
            {
                "event": "slm_analysis", 
                "timestamp": datetime.now().isoformat(),
                "message": "å°å‹èªè¨€æ¨¡å‹åˆ†æå®Œæˆ"
            },
            {
                "event": "jury_deliberation",
                "timestamp": datetime.now().isoformat(),
                "message": "é™ªå¯©åœ˜å¯©è­°å®Œæˆ"
            },
            {
                "event": "analysis_completed",
                "timestamp": datetime.now().isoformat(),
                "message": "åˆ†æå®Œæˆ"
            }
        ]
    }
    
    # æ›´æ–° session ç‹€æ…‹
    sessions_db[session_id]["state"] = analysis_result["state"]
    
    print(f"åˆ†æå®Œæˆ - Session: {session_id}")
    return analysis_result
